{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Predicting Optimal Makespan with Lenet-5 Mockup model with uncertainty\n",
    "## On Q Instances\n",
    "The notebook will be performing prediction of the optimal makespan.\n",
    "\n",
    "The output of this model should be a pandas dataframe where:\n",
    "- each row represent a single JSSP instances \n",
    "- each row contains information about ``name`` and ``predicted optimal makespan`` of the instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x7f39803f99a0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "# Specify which GPU(s) to use\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Or 2, 3, etc. other than 0\n",
    "\n",
    "# On CPU/GPU placement\n",
    "config = tf.compat.v1.ConfigProto(allow_soft_placement=True, log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.compat.v1.Session(config=config)\n",
    "\n",
    "# Note that ConfigProto disappeared in TF-2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RND_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(RND_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils.JsspInstanceParser import get_instance_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def combine_the_data(pickle_file, instance_file=\"../job-shop/job-shop-instances.hpp\", truncate=1.0):\n",
    "    benchmark_result_df = pd.read_pickle(pickle_file)\n",
    "    print(\"total log num = \", len(benchmark_result_df))\n",
    "    if truncate > -1.0 and truncate <0:\n",
    "        benchmark_result_df = benchmark_result_df[int(len(benchmark_result_df)*abs(truncate)):]\n",
    "    elif truncate < 1.0:\n",
    "        benchmark_result_df = benchmark_result_df[:int(len(benchmark_result_df)*truncate)]\n",
    "    elif truncate > 1.0:\n",
    "        benchmark_result_df = benchmark_result_df[:int(truncate)]\n",
    "    # prepare numerical input data\n",
    "    input_name_list = list(benchmark_result_df.columns.values)\n",
    "    input_name_list.remove('runtime_ms')\n",
    "    input_name_list.remove('probing_time_ms')\n",
    "    input_name_list.remove('adjusting_time_ms')\n",
    "    input_name_list.remove('solving_time_ms')\n",
    "    input_name_list.remove('makespan')\n",
    "    input_name_list.remove('Instance')\n",
    "    input_name_list.remove('Heuristic')\n",
    "    print(\"The numerical input data   are {}\".format(input_name_list))\n",
    "\n",
    "    input_data = benchmark_result_df[input_name_list]\n",
    "    X_numeric = input_data.to_numpy()\n",
    "\n",
    "    # perform one hot encoding on 'Heuristic'\n",
    "    enc = OneHotEncoder()\n",
    "    enc.fit(benchmark_result_df[['Heuristic']])\n",
    "    X_onehot = enc.transform(benchmark_result_df[['Heuristic']]).toarray()\n",
    "\n",
    "    # get the instance array \n",
    "    input_instance_name_list = benchmark_result_df['Instance'].to_numpy()\n",
    "    instance_dict = get_instance_dict(instance_file)\n",
    "    input_instance_array_list = [instance_dict[name]['instance_array'].reshape(instance_dict[name]['num_of_jobs'],-1) for name in input_instance_name_list]\n",
    "    X_instance = np.array(input_instance_array_list)\n",
    "    X_instance = np.expand_dims(X_instance, axis=-1)\n",
    "    # insanity check\n",
    "    for ind, val in enumerate(input_instance_array_list):\n",
    "        assert np.array_equal(X_instance[ind], np.expand_dims(val, axis=-1))\n",
    "    print(\"The shape of the instance array is {}\".format(X_instance.shape))\n",
    "    \n",
    "    X_instance_name_list = benchmark_result_df[['Instance']]\n",
    "    \n",
    "    \n",
    "    # merge the input data together\n",
    "    assert X_numeric.shape[0] == X_onehot.shape[0], \"Shape must be the same\"\n",
    "    X = np.hstack((X_numeric, X_onehot))\n",
    "    print(\"The shape of the input data is : \", X.shape)\n",
    "\n",
    "    # prepare the output data\n",
    "    y_makespan = benchmark_result_df['makespan'].to_numpy().reshape(-1, 1)\n",
    "    y_makespan = y_makespan.astype(np.dtype('int32'))\n",
    "    print(\"The shape of the output data (makespan) is : \", y_makespan.shape)\n",
    "\n",
    "    y_runtime = benchmark_result_df['runtime_ms'].to_numpy().reshape(-1, 1)\n",
    "    y_runtime = y_runtime.astype(np.dtype('int32'))\n",
    "    print(\"The shape of the output data (runtime) is : \", y_runtime.shape)\n",
    "    \n",
    "    return X, X_instance, X_instance_name_list, y_makespan, y_runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total log num =  10000\n",
      "The numerical input data   are ['tbf', 'first_LB', 'first_UB', 'first_makespan', 'probing_progress', 'num_of_jobs', 'num_of_machines', 'max_operation_time', 'max_machine_load', 'r_first_makespan_bound']\n",
      "Finish parsing 31162 jssp instances.\n",
      "The shape of the instance array is (10000, 9, 18, 1)\n",
      "The shape of the input data is :  (10000, 11)\n",
      "The shape of the output data (makespan) is :  (10000, 1)\n",
      "The shape of the output data (runtime) is :  (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "X, X_instance, X_instance_name_list, y_makespan, y_runtime = combine_the_data('./DL-Q10000_dataset/benchmark_result_df_DL_Q10000.pkl', truncate=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_train \t\t is (6000, 11)\n",
      "The shape of X_test \t\t is (4000, 11)\n",
      "The shape of X_instance_train \t is (6000, 9, 18, 1)\n",
      "The shape of X_instance_test \t is (4000, 9, 18, 1)\n",
      "The shape of y_makespan_train \t is (6000, 1)\n",
      "The shape of y_makespan_test \t is (4000, 1)\n",
      "The shape of y_runtime_train \t is (6000, 1)\n",
      "The shape of y_runtime_test \t is (4000, 1)\n",
      "The shape of X_instance_train_scaled_2channel \t\t is (6000, 9, 9, 2)\n",
      "The shape of X_instance_test_scaled_2channel \t\t is (4000, 9, 9, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, X_instance_train, X_instance_test, X_instance_name_list_train, X_instance_name_list_test, y_makespan_train, y_makespan_test, y_runtime_train, y_runtime_test = train_test_split(X, X_instance, X_instance_name_list, y_makespan, y_runtime, test_size=0.4, shuffle=True, random_state=RND_SEED)\n",
    "\n",
    "print(\"The shape of X_train \\t\\t is {}\".format(X_train.shape))\n",
    "print(\"The shape of X_test \\t\\t is {}\".format(X_test.shape))\n",
    "print(\"The shape of X_instance_train \\t is {}\".format(X_instance_train.shape))\n",
    "print(\"The shape of X_instance_test \\t is {}\".format(X_instance_test.shape))\n",
    "print(\"The shape of y_makespan_train \\t is {}\".format(y_makespan_train.shape))\n",
    "print(\"The shape of y_makespan_test \\t is {}\".format(y_makespan_test.shape))\n",
    "print(\"The shape of y_runtime_train \\t is {}\".format(y_runtime_train.shape))\n",
    "print(\"The shape of y_runtime_test \\t is {}\".format(y_runtime_test.shape))\n",
    "\n",
    "# X_scaled = StandardScaler().fit_transform(X[:, 1:],)\n",
    "X_std_scaler = StandardScaler()\n",
    "X_std_scaler.fit(X_train)\n",
    "X_train_scaled = X_std_scaler.transform(X_train)\n",
    "X_test_scaled = X_std_scaler.transform(X_test)\n",
    "\n",
    "instance_train_shape = X_instance_train.shape\n",
    "instance_test_shape = X_instance_test.shape\n",
    "\n",
    "X_instance_scaler = MinMaxScaler()\n",
    "X_instance_scaler.fit(X_instance_train.reshape(-1,1))\n",
    "X_instance_train_scaled = X_instance_scaler.transform(X_instance_train.reshape(-1,1)).reshape(instance_train_shape)\n",
    "X_instance_test_scaled = X_instance_scaler.transform(X_instance_test.reshape(-1,1)).reshape(instance_test_shape)\n",
    "# reform into channel\n",
    "X_instance_train_scaled_2channel = np.concatenate((X_instance_train_scaled[:, :, 0::2], X_instance_train_scaled[:, :, 1::2]), axis = 3)\n",
    "X_instance_test_scaled_2channel = np.concatenate((X_instance_test_scaled[:, :, 0::2], X_instance_test_scaled[:, :, 1::2]), axis = 3)\n",
    "\n",
    "print(\"The shape of X_instance_train_scaled_2channel \\t\\t is {}\".format(X_instance_train_scaled_2channel.shape))\n",
    "print(\"The shape of X_instance_test_scaled_2channel \\t\\t is {}\".format(X_instance_test_scaled_2channel.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Conv2D, DepthwiseConv2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_instance_input_shape = tuple(list(X_instance_train_scaled_2channel.shape)[1:])\n",
    "# aux_input_shape = X_instance_train_scaled.shape\n",
    "\n",
    "X_instance_input = Input(shape=X_instance_input_shape, name='JSSP_instance_input')\n",
    "\n",
    "X_instance = Conv2D(6, kernel_size=3, strides=(1,1), padding='valid', data_format='channels_last', activation='tanh')(X_instance_input)\n",
    "X_instance = DepthwiseConv2D(1, data_format='channels_last',activation='tanh')(X_instance)\n",
    "\n",
    "X_instance = Conv2D(16, kernel_size=3, strides=(1,1), padding='valid', data_format='channels_last', activation='tanh')(X_instance)\n",
    "X_instance = DepthwiseConv2D(1, data_format='channels_last',activation='tanh')(X_instance)\n",
    "\n",
    "\n",
    "X_instance = Conv2D(120, kernel_size=3, strides=(1,1), padding='valid', data_format='channels_last', activation='tanh')(X_instance)\n",
    "# X_instance = DepthwiseConv2D(1, data_format='channels_last',activation='tanh')(X_instance)\n",
    "\n",
    "\n",
    "X_instance = Flatten()(X_instance)\n",
    "\n",
    "# X_instance = Dense(32, activation='relu')(X_instance)\n",
    "# X_instance = Dropout(0.2)(X_instance, training=True)\n",
    "X_instance = Dense(32, activation='relu')(X_instance)\n",
    "X_instance = Dropout(0.1)(X_instance, training=True)\n",
    "X_instance = Dense(16, activation='relu')(X_instance)\n",
    "y = Dense(1)(X_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "JSSP_instance_input (InputLa [(None, 9, 9, 2)]         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 7, 7, 6)           114       \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d (DepthwiseC (None, 7, 7, 6)           12        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 5, 5, 16)          880       \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_1 (Depthwis (None, 5, 5, 16)          32        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 120)         17400     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1080)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                34592     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 53,575\n",
      "Trainable params: 53,575\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "makespan_instance_only_model = Model(inputs=[X_instance_input], outputs=[y])\n",
    "makespan_instance_only_model.compile(optimizer='adam', loss='mse')\n",
    "makespan_instance_only_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(makespan_instance_only_model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FOLDER = \"./model/\"\n",
    "TB_LOG_DIR = FOLDER + \"tf_logs/\"\n",
    "\n",
    "MODEL_DIR = FOLDER + \"model_checkpoint/\"\n",
    "\n",
    "GENERAL_MODEL_NAME = \"makespan_instance_only_Q_\"\n",
    "\n",
    "tb_makespan_instance_only = TensorBoard(log_dir=TB_LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_batch_size = 100\n",
    "VALIDATION_SPLIT = 1/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init_epoch = 0\n",
    "end_epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 1/50 [..............................] - ETA: 0s - loss: 542281.7500WARNING:tensorflow:From /home/bw/.local/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 421684.9375 - val_loss: 118509.3828\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 24810.5117 - val_loss: 6968.7334\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 7006.5815 - val_loss: 6934.3335\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 7184.6782 - val_loss: 6485.8877\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 7067.5488 - val_loss: 6779.7910\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 6917.3208 - val_loss: 6369.1582\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 6952.9751 - val_loss: 6343.4590\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 6694.4219 - val_loss: 6350.8428\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 6670.8530 - val_loss: 6110.2217\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 6744.4023 - val_loss: 6345.1021\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 6366.9790 - val_loss: 5993.1802\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 6814.2471 - val_loss: 6528.2710\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 6787.2446 - val_loss: 6314.8179\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 6771.5679 - val_loss: 6217.6221\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 6631.2192 - val_loss: 5833.6963\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 6670.6450 - val_loss: 6453.5981\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 6477.8262 - val_loss: 6104.3809\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 6580.9746 - val_loss: 6377.0269\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 6720.1777 - val_loss: 6069.8403\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 6768.1919 - val_loss: 6131.3984\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 6769.3442 - val_loss: 6019.9214\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 6907.2114 - val_loss: 6414.7168\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 6773.5518 - val_loss: 5873.8311\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 6869.8335 - val_loss: 6104.3374\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 6601.7964 - val_loss: 6222.0239\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 6497.7002 - val_loss: 6767.8486\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 6714.1470 - val_loss: 6121.4409\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 6422.9224 - val_loss: 5798.6084\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 6452.1484 - val_loss: 6538.8799\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 6251.7749 - val_loss: 5722.1860\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 6413.8818 - val_loss: 5823.6621\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 6315.5654 - val_loss: 6334.1670\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 6321.1733 - val_loss: 5643.9917\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 6322.3296 - val_loss: 5572.5542\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5868.5410 - val_loss: 5301.9990\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5957.2754 - val_loss: 6107.9219\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5990.4043 - val_loss: 5232.2993\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 6062.3340 - val_loss: 6456.4590\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 5934.4141 - val_loss: 5279.2368\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5897.9131 - val_loss: 5772.2129\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5856.7202 - val_loss: 5333.2119\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5678.9126 - val_loss: 5455.6113\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 6060.8867 - val_loss: 5619.4653\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 6149.5728 - val_loss: 5325.1440\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 6063.3276 - val_loss: 6534.5586\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5721.1807 - val_loss: 5501.2710\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5802.5483 - val_loss: 5801.8125\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5521.0898 - val_loss: 5571.2207\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5884.1094 - val_loss: 5503.8115\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5828.1123 - val_loss: 5031.5161\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5632.6587 - val_loss: 5442.0620\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5548.1094 - val_loss: 5511.7593\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5924.2642 - val_loss: 5366.4229\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5540.1162 - val_loss: 5737.5366\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5542.2148 - val_loss: 5505.4517\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5987.9365 - val_loss: 4788.0049\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5498.1870 - val_loss: 5028.6064\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5710.6782 - val_loss: 5032.0879\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5511.5542 - val_loss: 4717.5518\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5529.1167 - val_loss: 5247.7676\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5541.7168 - val_loss: 5061.9819\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5417.7881 - val_loss: 4995.5366\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5647.0518 - val_loss: 5286.3892\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5328.3174 - val_loss: 5219.5991\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5441.2090 - val_loss: 6174.0317\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5756.5059 - val_loss: 5596.7891\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5574.9985 - val_loss: 4995.1235\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5511.2427 - val_loss: 5215.8169\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5481.6577 - val_loss: 5291.4565\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5453.0806 - val_loss: 5137.8940\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5227.9399 - val_loss: 4936.2983\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5324.7637 - val_loss: 5115.4619\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5163.6582 - val_loss: 4840.6011\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5041.7549 - val_loss: 4744.5000\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5142.1948 - val_loss: 5483.2432\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5420.0010 - val_loss: 6298.8877\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5330.6118 - val_loss: 4966.0415\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5306.7622 - val_loss: 4723.5845\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5399.4502 - val_loss: 4895.9136\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5115.8159 - val_loss: 4705.6265\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5058.3892 - val_loss: 4489.1387\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5296.4302 - val_loss: 5004.0732\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5082.6592 - val_loss: 4783.9136\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4911.4795 - val_loss: 4827.8794\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5260.1016 - val_loss: 5128.0259\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5107.4546 - val_loss: 4515.4727\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5147.0342 - val_loss: 5030.6948\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5101.8066 - val_loss: 4778.1240\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5100.6196 - val_loss: 4698.1050\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4955.6777 - val_loss: 5223.5342\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5199.0923 - val_loss: 4883.5562\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5287.3564 - val_loss: 5072.5449\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5069.8330 - val_loss: 4464.8599\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4848.8052 - val_loss: 4861.7217\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5014.0474 - val_loss: 4669.2749\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5021.1958 - val_loss: 4647.9175\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4872.2837 - val_loss: 5116.0762\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5071.6821 - val_loss: 4425.8364\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5080.5005 - val_loss: 4759.8662\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5071.6890 - val_loss: 5358.1123\n",
      "CPU times: user 1min 45s, sys: 27.6 s, total: 2min 13s\n",
      "Wall time: 34.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f384a4d1340>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time makespan_instance_only_model.fit([X_instance_train_scaled_2channel], [y_makespan_train], epochs=end_epoch, batch_size=model_batch_size, validation_split=VALIDATION_SPLIT, callbacks=[tb_makespan_instance_only], initial_epoch=init_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 3ms/step - loss: 5656.4858\n",
      "CPU times: user 367 ms, sys: 71.8 ms, total: 439 ms\n",
      "Wall time: 164 ms\n",
      "Loss on test set is 5656.48583984375\n"
     ]
    }
   ],
   "source": [
    "%time makespan_instance_only_test_loss = makespan_instance_only_model.evaluate(x=[X_instance_test_scaled_2channel], y=[y_makespan_test], batch_size=model_batch_size)\n",
    "print(\"Loss on test set is {}\".format(makespan_instance_only_test_loss))\n",
    "makespan_instance_only_model.save(MODEL_DIR + GENERAL_MODEL_NAME + str(end_epoch) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init_epoch = 100\n",
    "end_epoch = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/200\n",
      " 1/50 [..............................] - ETA: 0s - loss: 6179.1494WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0063s vs `on_train_batch_end` time: 0.0138s). Check your callbacks.\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5082.6787 - val_loss: 4924.7681\n",
      "Epoch 102/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4974.4346 - val_loss: 4824.4121\n",
      "Epoch 103/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4951.0640 - val_loss: 4633.0225\n",
      "Epoch 104/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4944.6040 - val_loss: 4708.9692\n",
      "Epoch 105/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5186.7993 - val_loss: 4591.9585\n",
      "Epoch 106/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5109.4272 - val_loss: 4383.8613\n",
      "Epoch 107/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4944.4658 - val_loss: 4469.4502\n",
      "Epoch 108/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4892.7090 - val_loss: 4508.0386\n",
      "Epoch 109/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4935.9517 - val_loss: 4594.1992\n",
      "Epoch 110/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5066.6138 - val_loss: 4630.5601\n",
      "Epoch 111/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4807.1562 - val_loss: 5011.0874\n",
      "Epoch 112/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5072.4912 - val_loss: 4460.6206\n",
      "Epoch 113/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4769.5454 - val_loss: 4724.2524\n",
      "Epoch 114/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4831.9272 - val_loss: 4731.6113\n",
      "Epoch 115/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5046.4370 - val_loss: 4579.3003\n",
      "Epoch 116/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4895.1343 - val_loss: 4635.3867\n",
      "Epoch 117/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4975.8838 - val_loss: 5126.9038\n",
      "Epoch 118/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4940.1865 - val_loss: 4676.6021\n",
      "Epoch 119/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4991.6006 - val_loss: 4890.5444\n",
      "Epoch 120/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4950.4175 - val_loss: 4890.3945\n",
      "Epoch 121/200\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 4722.4683 - val_loss: 4426.1001\n",
      "Epoch 122/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4990.5498 - val_loss: 4782.6982\n",
      "Epoch 123/200\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 4958.4883 - val_loss: 4468.9702\n",
      "Epoch 124/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4818.4849 - val_loss: 4894.3306\n",
      "Epoch 125/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4844.8198 - val_loss: 4797.1133\n",
      "Epoch 126/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4925.7324 - val_loss: 5330.4604\n",
      "Epoch 127/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4866.7754 - val_loss: 4966.0640\n",
      "Epoch 128/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4921.2783 - val_loss: 4812.2451\n",
      "Epoch 129/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4949.8037 - val_loss: 4622.9937\n",
      "Epoch 130/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4868.9014 - val_loss: 4584.6782\n",
      "Epoch 131/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4917.6445 - val_loss: 4847.6475\n",
      "Epoch 132/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4866.3550 - val_loss: 4378.3696\n",
      "Epoch 133/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4915.3198 - val_loss: 4683.7910\n",
      "Epoch 134/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4911.4810 - val_loss: 4968.5781\n",
      "Epoch 135/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4877.4702 - val_loss: 4739.1953\n",
      "Epoch 136/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4959.5552 - val_loss: 4343.3340\n",
      "Epoch 137/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4989.1123 - val_loss: 4287.2339\n",
      "Epoch 138/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4813.4844 - val_loss: 4581.3989\n",
      "Epoch 139/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4844.8379 - val_loss: 4496.2827\n",
      "Epoch 140/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4932.5249 - val_loss: 4993.5874\n",
      "Epoch 141/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4735.5654 - val_loss: 4599.1885\n",
      "Epoch 142/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4940.3486 - val_loss: 4234.0566\n",
      "Epoch 143/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5232.0825 - val_loss: 4755.5410\n",
      "Epoch 144/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4671.3926 - val_loss: 5301.2300\n",
      "Epoch 145/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4704.2905 - val_loss: 4788.2280\n",
      "Epoch 146/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4767.7310 - val_loss: 4445.6152\n",
      "Epoch 147/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4777.2778 - val_loss: 4558.9575\n",
      "Epoch 148/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4951.5122 - val_loss: 4846.6807\n",
      "Epoch 149/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4830.3608 - val_loss: 4429.1997\n",
      "Epoch 150/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4947.0083 - val_loss: 4544.2466\n",
      "Epoch 151/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4746.8193 - val_loss: 5248.7788\n",
      "Epoch 152/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4811.1694 - val_loss: 4877.1421\n",
      "Epoch 153/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4952.9434 - val_loss: 4569.9160\n",
      "Epoch 154/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4667.2383 - val_loss: 4365.6226\n",
      "Epoch 155/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5106.3506 - val_loss: 4475.4233\n",
      "Epoch 156/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4755.7700 - val_loss: 4307.6851\n",
      "Epoch 157/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4726.2173 - val_loss: 4281.3892\n",
      "Epoch 158/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4646.8394 - val_loss: 4635.6294\n",
      "Epoch 159/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4725.0078 - val_loss: 4838.8843\n",
      "Epoch 160/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4725.0107 - val_loss: 4682.2578\n",
      "Epoch 161/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4848.1821 - val_loss: 4779.2358\n",
      "Epoch 162/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4672.0835 - val_loss: 4649.0518\n",
      "Epoch 163/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4832.2793 - val_loss: 4662.9409\n",
      "Epoch 164/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4830.2544 - val_loss: 4809.0459\n",
      "Epoch 165/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4607.2393 - val_loss: 4384.5864\n",
      "Epoch 166/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4724.4634 - val_loss: 4331.7769\n",
      "Epoch 167/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4861.2007 - val_loss: 4741.1411\n",
      "Epoch 168/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4728.0474 - val_loss: 4428.6567\n",
      "Epoch 169/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4819.6182 - val_loss: 4834.6133\n",
      "Epoch 170/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4796.2324 - val_loss: 4921.8018\n",
      "Epoch 171/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4712.3750 - val_loss: 4627.5430\n",
      "Epoch 172/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5009.9097 - val_loss: 4507.7666\n",
      "Epoch 173/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4712.6851 - val_loss: 4621.3760\n",
      "Epoch 174/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4657.4546 - val_loss: 4406.2007\n",
      "Epoch 175/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4880.7632 - val_loss: 4202.1318\n",
      "Epoch 176/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4649.4565 - val_loss: 4737.0015\n",
      "Epoch 177/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4819.9473 - val_loss: 4606.4014\n",
      "Epoch 178/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4695.0381 - val_loss: 4550.6025\n",
      "Epoch 179/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4796.3931 - val_loss: 4453.6270\n",
      "Epoch 180/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4854.1509 - val_loss: 4339.8135\n",
      "Epoch 181/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4817.8730 - val_loss: 4682.1816\n",
      "Epoch 182/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4890.1665 - val_loss: 4210.1006\n",
      "Epoch 183/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4686.6138 - val_loss: 4372.6699\n",
      "Epoch 184/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4926.1450 - val_loss: 4730.8770\n",
      "Epoch 185/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 5014.2837 - val_loss: 4621.3887\n",
      "Epoch 186/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4756.5923 - val_loss: 5070.9043\n",
      "Epoch 187/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4887.0366 - val_loss: 4574.9868\n",
      "Epoch 188/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4905.0522 - val_loss: 4231.1094\n",
      "Epoch 189/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4871.0337 - val_loss: 4575.0820\n",
      "Epoch 190/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4630.6431 - val_loss: 4438.6943\n",
      "Epoch 191/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4774.7119 - val_loss: 4925.7856\n",
      "Epoch 192/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4700.8301 - val_loss: 4632.0298\n",
      "Epoch 193/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4912.5732 - val_loss: 4247.9541\n",
      "Epoch 194/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4663.1538 - val_loss: 4165.3076\n",
      "Epoch 195/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4742.5454 - val_loss: 4367.9629\n",
      "Epoch 196/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4833.4058 - val_loss: 4763.7651\n",
      "Epoch 197/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4640.6240 - val_loss: 4452.0654\n",
      "Epoch 198/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4702.7710 - val_loss: 4909.9800\n",
      "Epoch 199/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4827.0698 - val_loss: 4407.8384\n",
      "Epoch 200/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4819.3271 - val_loss: 4613.5073\n",
      "CPU times: user 1min 43s, sys: 29.3 s, total: 2min 12s\n",
      "Wall time: 34.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f384f3cbd60>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time makespan_instance_only_model.fit([X_instance_train_scaled_2channel], [y_makespan_train], epochs=end_epoch, batch_size=model_batch_size, validation_split=VALIDATION_SPLIT, callbacks=[tb_makespan_instance_only], initial_epoch=init_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 3ms/step - loss: 4863.3916\n",
      "CPU times: user 343 ms, sys: 88.8 ms, total: 432 ms\n",
      "Wall time: 166 ms\n",
      "Loss on test set is 4863.3916015625\n"
     ]
    }
   ],
   "source": [
    "%time makespan_instance_only_test_loss = makespan_instance_only_model.evaluate(x=[X_instance_test_scaled_2channel], y=[y_makespan_test], batch_size=model_batch_size)\n",
    "print(\"Loss on test set is {}\".format(makespan_instance_only_test_loss))\n",
    "makespan_instance_only_model.save(MODEL_DIR + GENERAL_MODEL_NAME + str(end_epoch) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init_epoch = 200\n",
    "end_epoch = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4701.4116 - val_loss: 4781.4409\n",
      "Epoch 202/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4667.5518 - val_loss: 4295.7710\n",
      "Epoch 203/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4650.1162 - val_loss: 4858.1787\n",
      "Epoch 204/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4928.2593 - val_loss: 4941.8257\n",
      "Epoch 205/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4822.5493 - val_loss: 4406.8872\n",
      "Epoch 206/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4648.9150 - val_loss: 4295.5913\n",
      "Epoch 207/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4714.5142 - val_loss: 4297.4517\n",
      "Epoch 208/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4943.8643 - val_loss: 4967.3926\n",
      "Epoch 209/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4900.6509 - val_loss: 4229.6768\n",
      "Epoch 210/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4623.6958 - val_loss: 5191.9097\n",
      "Epoch 211/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4875.8662 - val_loss: 4621.8584\n",
      "Epoch 212/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4888.1157 - val_loss: 5035.9595\n",
      "Epoch 213/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4772.2729 - val_loss: 4076.5391\n",
      "Epoch 214/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4627.3530 - val_loss: 4488.9214\n",
      "Epoch 215/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4830.4775 - val_loss: 4915.1523\n",
      "Epoch 216/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4847.4570 - val_loss: 4426.8872\n",
      "Epoch 217/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4765.6338 - val_loss: 4724.4985\n",
      "Epoch 218/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4665.7388 - val_loss: 4435.5259\n",
      "Epoch 219/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4878.3853 - val_loss: 4491.3813\n",
      "Epoch 220/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4994.2783 - val_loss: 4321.8198\n",
      "Epoch 221/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4812.8105 - val_loss: 4598.6245\n",
      "Epoch 222/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4601.3735 - val_loss: 4287.5220\n",
      "Epoch 223/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4770.7368 - val_loss: 4064.7424\n",
      "Epoch 224/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4674.2734 - val_loss: 4396.9741\n",
      "Epoch 225/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4694.7412 - val_loss: 4626.1948\n",
      "Epoch 226/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4570.1606 - val_loss: 4328.1582\n",
      "Epoch 227/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4816.2954 - val_loss: 5294.6519\n",
      "Epoch 228/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4837.3022 - val_loss: 4446.6685\n",
      "Epoch 229/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4651.6841 - val_loss: 4253.9927\n",
      "Epoch 230/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4660.5273 - val_loss: 4579.9805\n",
      "Epoch 231/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4539.3433 - val_loss: 4212.4609\n",
      "Epoch 232/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4577.9805 - val_loss: 4647.1299\n",
      "Epoch 233/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4709.1846 - val_loss: 4734.1660\n",
      "Epoch 234/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4859.2778 - val_loss: 4400.2632\n",
      "Epoch 235/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4571.3418 - val_loss: 4518.6533\n",
      "Epoch 236/300\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 5094.4805 - val_loss: 4007.5376\n",
      "Epoch 237/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4754.7622 - val_loss: 4350.9482\n",
      "Epoch 238/300\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 4515.1382 - val_loss: 4370.3335\n",
      "Epoch 239/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4584.9189 - val_loss: 4920.6230\n",
      "Epoch 240/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4746.3652 - val_loss: 4276.9639\n",
      "Epoch 241/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4681.8608 - val_loss: 4232.2461\n",
      "Epoch 242/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4530.4302 - val_loss: 4685.2129\n",
      "Epoch 243/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4763.6069 - val_loss: 4353.7671\n",
      "Epoch 244/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4595.3218 - val_loss: 4489.9995\n",
      "Epoch 245/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4772.1758 - val_loss: 4469.5879\n",
      "Epoch 246/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4613.5225 - val_loss: 4261.6152\n",
      "Epoch 247/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4644.6763 - val_loss: 4392.6812\n",
      "Epoch 248/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4635.7778 - val_loss: 4868.2852\n",
      "Epoch 249/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4700.3335 - val_loss: 4549.5947\n",
      "Epoch 250/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4607.5435 - val_loss: 5005.9497\n",
      "Epoch 251/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4586.2661 - val_loss: 4417.0029\n",
      "Epoch 252/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4831.4292 - val_loss: 4487.8560\n",
      "Epoch 253/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4607.4805 - val_loss: 4484.7427\n",
      "Epoch 254/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4626.9424 - val_loss: 4633.0039\n",
      "Epoch 255/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4654.0850 - val_loss: 4567.7788\n",
      "Epoch 256/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4839.1348 - val_loss: 4236.6094\n",
      "Epoch 257/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4586.0381 - val_loss: 4480.5684\n",
      "Epoch 258/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4668.6050 - val_loss: 4934.3545\n",
      "Epoch 259/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4706.9155 - val_loss: 4585.2632\n",
      "Epoch 260/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4744.3032 - val_loss: 4276.0586\n",
      "Epoch 261/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4516.5649 - val_loss: 4748.7939\n",
      "Epoch 262/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4603.1274 - val_loss: 4532.4229\n",
      "Epoch 263/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4640.2207 - val_loss: 4274.2017\n",
      "Epoch 264/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4761.6006 - val_loss: 4291.3525\n",
      "Epoch 265/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4714.0400 - val_loss: 4181.1738\n",
      "Epoch 266/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4741.1118 - val_loss: 5064.4302\n",
      "Epoch 267/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4618.9062 - val_loss: 4855.1509\n",
      "Epoch 268/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4628.7642 - val_loss: 4323.9238\n",
      "Epoch 269/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4537.8320 - val_loss: 4224.4312\n",
      "Epoch 270/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4788.0161 - val_loss: 4596.4678\n",
      "Epoch 271/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4564.3452 - val_loss: 4194.8389\n",
      "Epoch 272/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4587.6606 - val_loss: 4391.3115\n",
      "Epoch 273/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4715.4990 - val_loss: 4549.2305\n",
      "Epoch 274/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4776.1304 - val_loss: 4018.1882\n",
      "Epoch 275/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4623.0034 - val_loss: 4603.9141\n",
      "Epoch 276/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4510.1455 - val_loss: 4905.8218\n",
      "Epoch 277/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4545.4873 - val_loss: 4467.9326\n",
      "Epoch 278/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4772.3887 - val_loss: 4425.7080\n",
      "Epoch 279/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4500.9829 - val_loss: 4677.4150\n",
      "Epoch 280/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4408.9858 - val_loss: 4219.7261\n",
      "Epoch 281/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4419.7642 - val_loss: 4337.9590\n",
      "Epoch 282/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4557.9170 - val_loss: 4063.1685\n",
      "Epoch 283/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4545.5479 - val_loss: 4266.9209\n",
      "Epoch 284/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4680.7544 - val_loss: 4307.0693\n",
      "Epoch 285/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4520.8618 - val_loss: 4001.4917\n",
      "Epoch 286/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4466.7832 - val_loss: 4214.0947\n",
      "Epoch 287/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4479.3774 - val_loss: 4673.6426\n",
      "Epoch 288/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4659.7935 - val_loss: 4264.3037\n",
      "Epoch 289/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4646.3311 - val_loss: 4361.9819\n",
      "Epoch 290/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4655.3555 - val_loss: 5602.5005\n",
      "Epoch 291/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4849.3613 - val_loss: 4434.8770\n",
      "Epoch 292/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4692.4526 - val_loss: 5705.4512\n",
      "Epoch 293/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4753.3232 - val_loss: 4270.0542\n",
      "Epoch 294/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4417.5752 - val_loss: 4727.2061\n",
      "Epoch 295/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4551.6279 - val_loss: 4474.6416\n",
      "Epoch 296/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4610.4062 - val_loss: 4424.6226\n",
      "Epoch 297/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4674.7642 - val_loss: 4523.2661\n",
      "Epoch 298/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4689.0654 - val_loss: 4423.1294\n",
      "Epoch 299/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4492.4170 - val_loss: 4215.2080\n",
      "Epoch 300/300\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4537.7754 - val_loss: 4328.6743\n",
      "CPU times: user 1min 45s, sys: 28.5 s, total: 2min 14s\n",
      "Wall time: 34.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f384f2bbc10>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time makespan_instance_only_model.fit([X_instance_train_scaled_2channel], [y_makespan_train], epochs=end_epoch, batch_size=model_batch_size, validation_split=VALIDATION_SPLIT, callbacks=[tb_makespan_instance_only], initial_epoch=init_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 3ms/step - loss: 4474.8169\n",
      "CPU times: user 391 ms, sys: 32 ms, total: 423 ms\n",
      "Wall time: 163 ms\n",
      "Loss on test set is 4474.81689453125\n"
     ]
    }
   ],
   "source": [
    "%time makespan_instance_only_test_loss = makespan_instance_only_model.evaluate(x=[X_instance_test_scaled_2channel], y=[y_makespan_test], batch_size=model_batch_size)\n",
    "print(\"Loss on test set is {}\".format(makespan_instance_only_test_loss))\n",
    "makespan_instance_only_model.save(MODEL_DIR + GENERAL_MODEL_NAME + str(end_epoch) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init_epoch = 300\n",
    "end_epoch = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4735.5820 - val_loss: 4734.4980\n",
      "Epoch 302/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4698.3179 - val_loss: 5041.9863\n",
      "Epoch 303/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4562.2974 - val_loss: 4485.3628\n",
      "Epoch 304/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4680.1074 - val_loss: 4498.4155\n",
      "Epoch 305/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4669.3765 - val_loss: 4723.1074\n",
      "Epoch 306/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4748.7671 - val_loss: 4216.4663\n",
      "Epoch 307/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4611.6768 - val_loss: 4652.1509\n",
      "Epoch 308/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4554.4458 - val_loss: 4483.1523\n",
      "Epoch 309/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4576.5210 - val_loss: 4264.0547\n",
      "Epoch 310/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4540.6792 - val_loss: 4522.1763\n",
      "Epoch 311/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4607.7310 - val_loss: 4690.3521\n",
      "Epoch 312/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4510.7554 - val_loss: 4537.6636\n",
      "Epoch 313/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4690.0586 - val_loss: 4695.0234\n",
      "Epoch 314/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4588.5840 - val_loss: 4579.5137\n",
      "Epoch 315/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4673.4458 - val_loss: 4475.5859\n",
      "Epoch 316/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4626.1753 - val_loss: 4377.0288\n",
      "Epoch 317/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4746.4722 - val_loss: 4482.3389\n",
      "Epoch 318/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4469.0869 - val_loss: 4453.0337\n",
      "Epoch 319/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4484.0757 - val_loss: 4289.0908\n",
      "Epoch 320/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4697.2300 - val_loss: 4600.3496\n",
      "Epoch 321/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4604.9019 - val_loss: 4594.3008\n",
      "Epoch 322/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4627.1836 - val_loss: 4236.7964\n",
      "Epoch 323/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4627.4624 - val_loss: 4129.8477\n",
      "Epoch 324/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4537.1392 - val_loss: 4425.7852\n",
      "Epoch 325/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4554.8799 - val_loss: 4335.8115\n",
      "Epoch 326/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4485.6982 - val_loss: 4700.8477\n",
      "Epoch 327/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4696.7729 - val_loss: 4794.4966\n",
      "Epoch 328/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4488.0420 - val_loss: 4582.1987\n",
      "Epoch 329/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4529.5083 - val_loss: 4584.7568\n",
      "Epoch 330/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4541.7192 - val_loss: 4278.0244\n",
      "Epoch 331/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4576.6260 - val_loss: 4158.1499\n",
      "Epoch 332/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4629.9702 - val_loss: 4413.3901\n",
      "Epoch 333/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4506.7612 - val_loss: 4385.7964\n",
      "Epoch 334/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4577.8794 - val_loss: 4426.5879\n",
      "Epoch 335/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4596.0620 - val_loss: 4027.1592\n",
      "Epoch 336/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4552.7310 - val_loss: 4591.8208\n",
      "Epoch 337/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4482.5298 - val_loss: 4252.9521\n",
      "Epoch 338/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4738.2974 - val_loss: 4226.8765\n",
      "Epoch 339/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4532.3560 - val_loss: 4422.5190\n",
      "Epoch 340/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4488.5898 - val_loss: 4384.5532\n",
      "Epoch 341/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4682.7158 - val_loss: 4421.4917\n",
      "Epoch 342/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4609.2144 - val_loss: 4160.7847\n",
      "Epoch 343/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4720.8081 - val_loss: 4335.8091\n",
      "Epoch 344/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4401.5161 - val_loss: 4165.6968\n",
      "Epoch 345/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4439.8643 - val_loss: 4328.8066\n",
      "Epoch 346/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4549.7290 - val_loss: 4600.0083\n",
      "Epoch 347/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4630.8101 - val_loss: 4702.1982\n",
      "Epoch 348/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4523.9277 - val_loss: 4511.8643\n",
      "Epoch 349/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4550.2339 - val_loss: 4290.3862\n",
      "Epoch 350/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4621.4854 - val_loss: 4385.0947\n",
      "Epoch 351/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4692.1680 - val_loss: 4279.4019\n",
      "Epoch 352/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4551.0034 - val_loss: 4631.4668\n",
      "Epoch 353/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4573.5776 - val_loss: 4468.8369\n",
      "Epoch 354/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4506.5830 - val_loss: 4280.3301\n",
      "Epoch 355/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4570.5503 - val_loss: 4686.3613\n",
      "Epoch 356/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4426.9775 - val_loss: 4238.2056\n",
      "Epoch 357/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4545.6152 - val_loss: 4509.0259\n",
      "Epoch 358/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4515.4688 - val_loss: 4442.4829\n",
      "Epoch 359/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4737.8291 - val_loss: 4153.8413\n",
      "Epoch 360/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4607.9697 - val_loss: 4552.5088\n",
      "Epoch 361/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4539.4336 - val_loss: 4496.9893\n",
      "Epoch 362/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4499.0264 - val_loss: 4399.7241\n",
      "Epoch 363/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4640.2524 - val_loss: 4491.7549\n",
      "Epoch 364/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4558.5371 - val_loss: 3868.5576\n",
      "Epoch 365/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4581.4028 - val_loss: 4803.5156\n",
      "Epoch 366/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4386.3320 - val_loss: 4549.1592\n",
      "Epoch 367/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4401.2002 - val_loss: 4743.0098\n",
      "Epoch 368/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4573.6943 - val_loss: 4163.7930\n",
      "Epoch 369/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4397.2168 - val_loss: 4026.1711\n",
      "Epoch 370/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4522.9053 - val_loss: 4272.9668\n",
      "Epoch 371/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4593.2280 - val_loss: 4276.6787\n",
      "Epoch 372/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4641.9458 - val_loss: 4464.2432\n",
      "Epoch 373/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4357.3374 - val_loss: 4471.1943\n",
      "Epoch 374/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4634.6362 - val_loss: 4211.7690\n",
      "Epoch 375/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4558.9810 - val_loss: 4258.2378\n",
      "Epoch 376/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4513.0630 - val_loss: 4029.7131\n",
      "Epoch 377/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4406.1943 - val_loss: 4218.6372\n",
      "Epoch 378/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4470.1064 - val_loss: 4224.6558\n",
      "Epoch 379/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4493.4082 - val_loss: 4232.1450\n",
      "Epoch 380/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4601.0400 - val_loss: 4490.5396\n",
      "Epoch 381/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4493.2617 - val_loss: 4255.0347\n",
      "Epoch 382/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4386.7173 - val_loss: 4288.7144\n",
      "Epoch 383/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4401.1777 - val_loss: 4594.9219\n",
      "Epoch 384/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4530.3921 - val_loss: 4045.4929\n",
      "Epoch 385/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4420.7217 - val_loss: 4370.6108\n",
      "Epoch 386/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4373.2754 - val_loss: 4236.2158\n",
      "Epoch 387/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4410.6382 - val_loss: 4361.2832\n",
      "Epoch 388/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4644.1616 - val_loss: 4628.8281\n",
      "Epoch 389/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4422.4277 - val_loss: 3970.0503\n",
      "Epoch 390/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4572.9229 - val_loss: 4266.7437\n",
      "Epoch 391/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4345.6001 - val_loss: 4426.0708\n",
      "Epoch 392/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4392.9546 - val_loss: 4232.2305\n",
      "Epoch 393/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4537.3960 - val_loss: 4637.1060\n",
      "Epoch 394/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4598.0698 - val_loss: 4385.9585\n",
      "Epoch 395/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4474.7544 - val_loss: 4547.5713\n",
      "Epoch 396/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4485.3032 - val_loss: 4578.7334\n",
      "Epoch 397/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4514.2295 - val_loss: 3887.9038\n",
      "Epoch 398/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4354.8979 - val_loss: 4190.3027\n",
      "Epoch 399/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4442.9668 - val_loss: 4236.5459\n",
      "Epoch 400/400\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4455.2568 - val_loss: 4728.8413\n",
      "CPU times: user 1min 43s, sys: 28.3 s, total: 2min 11s\n",
      "Wall time: 34 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f38497a8c70>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time makespan_instance_only_model.fit([X_instance_train_scaled_2channel], [y_makespan_train], epochs=end_epoch, batch_size=model_batch_size, validation_split=VALIDATION_SPLIT, callbacks=[tb_makespan_instance_only], initial_epoch=init_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 3ms/step - loss: 4821.2236\n",
      "CPU times: user 406 ms, sys: 17 ms, total: 423 ms\n",
      "Wall time: 162 ms\n",
      "Loss on test set is 4821.2236328125\n"
     ]
    }
   ],
   "source": [
    "%time makespan_instance_only_test_loss = makespan_instance_only_model.evaluate(x=[X_instance_test_scaled_2channel], y=[y_makespan_test], batch_size=model_batch_size)\n",
    "print(\"Loss on test set is {}\".format(makespan_instance_only_test_loss))\n",
    "makespan_instance_only_model.save(MODEL_DIR + GENERAL_MODEL_NAME + str(end_epoch) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init_epoch = 400\n",
    "end_epoch = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 401/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4486.6138 - val_loss: 4340.1743\n",
      "Epoch 402/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4387.2104 - val_loss: 3958.3069\n",
      "Epoch 403/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4572.6030 - val_loss: 4350.5430\n",
      "Epoch 404/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4517.5039 - val_loss: 4069.2334\n",
      "Epoch 405/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4416.0962 - val_loss: 4460.4331\n",
      "Epoch 406/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4576.9482 - val_loss: 4636.7266\n",
      "Epoch 407/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4481.1802 - val_loss: 4212.2412\n",
      "Epoch 408/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4440.7563 - val_loss: 4262.4448\n",
      "Epoch 409/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4455.5474 - val_loss: 4316.3184\n",
      "Epoch 410/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4435.7974 - val_loss: 4571.3506\n",
      "Epoch 411/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4434.0234 - val_loss: 4270.4683\n",
      "Epoch 412/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4473.7109 - val_loss: 4118.2788\n",
      "Epoch 413/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4414.1899 - val_loss: 4087.6228\n",
      "Epoch 414/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4502.4512 - val_loss: 4360.8027\n",
      "Epoch 415/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4413.9766 - val_loss: 4417.1885\n",
      "Epoch 416/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4360.5630 - val_loss: 4238.1802\n",
      "Epoch 417/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4508.8174 - val_loss: 4339.4131\n",
      "Epoch 418/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4370.2334 - val_loss: 4266.4766\n",
      "Epoch 419/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4567.5894 - val_loss: 4435.0850\n",
      "Epoch 420/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4742.0010 - val_loss: 4338.0391\n",
      "Epoch 421/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4323.3896 - val_loss: 4294.7695\n",
      "Epoch 422/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4569.7329 - val_loss: 4360.5791\n",
      "Epoch 423/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4356.9150 - val_loss: 4069.9136\n",
      "Epoch 424/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4454.9575 - val_loss: 4313.4932\n",
      "Epoch 425/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4312.6006 - val_loss: 4654.1523\n",
      "Epoch 426/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4502.8545 - val_loss: 4142.8359\n",
      "Epoch 427/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4448.6299 - val_loss: 4155.2935\n",
      "Epoch 428/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4423.5776 - val_loss: 4481.4009\n",
      "Epoch 429/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4646.6689 - val_loss: 4456.5781\n",
      "Epoch 430/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4519.6128 - val_loss: 4472.8579\n",
      "Epoch 431/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4419.2339 - val_loss: 4387.4141\n",
      "Epoch 432/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4487.5649 - val_loss: 4011.5947\n",
      "Epoch 433/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4390.2432 - val_loss: 4184.4229\n",
      "Epoch 434/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4284.8950 - val_loss: 4351.0127\n",
      "Epoch 435/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4514.0981 - val_loss: 4057.8623\n",
      "Epoch 436/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4299.1484 - val_loss: 4250.9551\n",
      "Epoch 437/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4355.4814 - val_loss: 4328.1875\n",
      "Epoch 438/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4293.2466 - val_loss: 4057.9678\n",
      "Epoch 439/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4206.6230 - val_loss: 4120.1753\n",
      "Epoch 440/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4374.3315 - val_loss: 4363.1362\n",
      "Epoch 441/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4429.4277 - val_loss: 4088.8945\n",
      "Epoch 442/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4441.2046 - val_loss: 4069.1692\n",
      "Epoch 443/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4599.4917 - val_loss: 4369.3481\n",
      "Epoch 444/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4510.3501 - val_loss: 4419.7080\n",
      "Epoch 445/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4542.1572 - val_loss: 4219.5669\n",
      "Epoch 446/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4540.5112 - val_loss: 4355.9707\n",
      "Epoch 447/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4218.4771 - val_loss: 4088.0950\n",
      "Epoch 448/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4498.0703 - val_loss: 4335.6294\n",
      "Epoch 449/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4381.7466 - val_loss: 4176.6714\n",
      "Epoch 450/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4377.4351 - val_loss: 4335.9009\n",
      "Epoch 451/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4243.5283 - val_loss: 4464.7173\n",
      "Epoch 452/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4466.3330 - val_loss: 4200.7842\n",
      "Epoch 453/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4293.9116 - val_loss: 4038.3066\n",
      "Epoch 454/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4463.9238 - val_loss: 4159.1958\n",
      "Epoch 455/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4447.1562 - val_loss: 4170.1875\n",
      "Epoch 456/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4462.7773 - val_loss: 4119.4780\n",
      "Epoch 457/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4462.8257 - val_loss: 4390.0503\n",
      "Epoch 458/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4357.5044 - val_loss: 4156.9175\n",
      "Epoch 459/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4518.3838 - val_loss: 4463.0244\n",
      "Epoch 460/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4306.9976 - val_loss: 4284.9531\n",
      "Epoch 461/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4297.1519 - val_loss: 4750.9307\n",
      "Epoch 462/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4448.9712 - val_loss: 4147.8140\n",
      "Epoch 463/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4340.5884 - val_loss: 4137.8384\n",
      "Epoch 464/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4474.7368 - val_loss: 4165.6689\n",
      "Epoch 465/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4330.3135 - val_loss: 4505.0210\n",
      "Epoch 466/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4315.9502 - val_loss: 4130.5083\n",
      "Epoch 467/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4236.1318 - val_loss: 4247.9731\n",
      "Epoch 468/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4541.6235 - val_loss: 4585.1738\n",
      "Epoch 469/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4562.8765 - val_loss: 4426.9985\n",
      "Epoch 470/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4242.9634 - val_loss: 3887.6860\n",
      "Epoch 471/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4441.5786 - val_loss: 4335.4561\n",
      "Epoch 472/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4256.6685 - val_loss: 4332.6860\n",
      "Epoch 473/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4527.7720 - val_loss: 3894.1902\n",
      "Epoch 474/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4290.8682 - val_loss: 4034.3877\n",
      "Epoch 475/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4193.4263 - val_loss: 4715.5444\n",
      "Epoch 476/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4387.2222 - val_loss: 4369.7930\n",
      "Epoch 477/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4322.6191 - val_loss: 4293.8174\n",
      "Epoch 478/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4314.8979 - val_loss: 4084.4565\n",
      "Epoch 479/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4304.9375 - val_loss: 4291.1313\n",
      "Epoch 480/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4295.1709 - val_loss: 4165.4941\n",
      "Epoch 481/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4166.7803 - val_loss: 4126.5474\n",
      "Epoch 482/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4394.6050 - val_loss: 4296.8716\n",
      "Epoch 483/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4443.6870 - val_loss: 4184.1963\n",
      "Epoch 484/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4360.1582 - val_loss: 4553.1753\n",
      "Epoch 485/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4542.8550 - val_loss: 3699.8086\n",
      "Epoch 486/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4319.7310 - val_loss: 4170.6406\n",
      "Epoch 487/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4244.7749 - val_loss: 4179.4082\n",
      "Epoch 488/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4207.8149 - val_loss: 4057.0513\n",
      "Epoch 489/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4569.7549 - val_loss: 4115.1357\n",
      "Epoch 490/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4269.1455 - val_loss: 4245.2446\n",
      "Epoch 491/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4284.1084 - val_loss: 4122.5015\n",
      "Epoch 492/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4311.8179 - val_loss: 3857.4004\n",
      "Epoch 493/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4382.3062 - val_loss: 4110.5747\n",
      "Epoch 494/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4242.0645 - val_loss: 4288.7080\n",
      "Epoch 495/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4334.8931 - val_loss: 4125.4053\n",
      "Epoch 496/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4153.9077 - val_loss: 4121.6514\n",
      "Epoch 497/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4333.5635 - val_loss: 4098.9019\n",
      "Epoch 498/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4139.6138 - val_loss: 4118.8384\n",
      "Epoch 499/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4195.0000 - val_loss: 4295.8682\n",
      "Epoch 500/500\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4260.1582 - val_loss: 4051.3943\n",
      "CPU times: user 1min 44s, sys: 28 s, total: 2min 12s\n",
      "Wall time: 34.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f384eacbe20>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time makespan_instance_only_model.fit([X_instance_train_scaled_2channel], [y_makespan_train], epochs=end_epoch, batch_size=model_batch_size, validation_split=VALIDATION_SPLIT, callbacks=[tb_makespan_instance_only], initial_epoch=init_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 3ms/step - loss: 4243.1714\n",
      "CPU times: user 282 ms, sys: 127 ms, total: 408 ms\n",
      "Wall time: 159 ms\n",
      "Loss on test set is 4243.17138671875\n"
     ]
    }
   ],
   "source": [
    "%time makespan_instance_only_test_loss = makespan_instance_only_model.evaluate(x=[X_instance_test_scaled_2channel], y=[y_makespan_test], batch_size=model_batch_size)\n",
    "print(\"Loss on test set is {}\".format(makespan_instance_only_test_loss))\n",
    "makespan_instance_only_model.save(MODEL_DIR + GENERAL_MODEL_NAME + str(end_epoch) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init_epoch = 500\n",
    "end_epoch = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 501/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4202.0718 - val_loss: 3842.5085\n",
      "Epoch 502/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4353.2588 - val_loss: 4176.5288\n",
      "Epoch 503/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4239.9233 - val_loss: 3873.7229\n",
      "Epoch 504/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4219.6460 - val_loss: 3805.7842\n",
      "Epoch 505/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4234.0078 - val_loss: 4210.3750\n",
      "Epoch 506/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4369.3130 - val_loss: 4350.6616\n",
      "Epoch 507/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4354.1450 - val_loss: 3933.4714\n",
      "Epoch 508/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4376.8403 - val_loss: 3936.0693\n",
      "Epoch 509/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4379.7266 - val_loss: 4108.9980\n",
      "Epoch 510/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4405.5527 - val_loss: 4082.7571\n",
      "Epoch 511/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4360.5190 - val_loss: 3944.0962\n",
      "Epoch 512/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4348.8159 - val_loss: 4210.1953\n",
      "Epoch 513/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4349.4600 - val_loss: 4303.5957\n",
      "Epoch 514/600\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 4218.4917 - val_loss: 4184.6660\n",
      "Epoch 515/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4282.7754 - val_loss: 4518.3071\n",
      "Epoch 516/600\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 4325.5698 - val_loss: 3879.3279\n",
      "Epoch 517/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4341.1372 - val_loss: 3731.5134\n",
      "Epoch 518/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4200.1890 - val_loss: 4179.5503\n",
      "Epoch 519/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4359.0078 - val_loss: 4205.9277\n",
      "Epoch 520/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4250.3096 - val_loss: 4201.3804\n",
      "Epoch 521/600\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 4204.4375 - val_loss: 4360.1431\n",
      "Epoch 522/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4292.2236 - val_loss: 4246.8203\n",
      "Epoch 523/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4363.7798 - val_loss: 4300.3848\n",
      "Epoch 524/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4178.0918 - val_loss: 4102.2793\n",
      "Epoch 525/600\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 4166.8423 - val_loss: 3747.7166\n",
      "Epoch 526/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4387.9600 - val_loss: 3996.7014\n",
      "Epoch 527/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4257.4346 - val_loss: 4245.8813\n",
      "Epoch 528/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4043.4836 - val_loss: 4035.6558\n",
      "Epoch 529/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4185.9526 - val_loss: 3954.7922\n",
      "Epoch 530/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4359.7246 - val_loss: 4167.8120\n",
      "Epoch 531/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4199.8901 - val_loss: 4488.3032\n",
      "Epoch 532/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4156.1636 - val_loss: 4252.2583\n",
      "Epoch 533/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4217.6787 - val_loss: 4201.0166\n",
      "Epoch 534/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4320.2402 - val_loss: 3638.8813\n",
      "Epoch 535/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4311.0474 - val_loss: 4162.6123\n",
      "Epoch 536/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4252.8550 - val_loss: 4184.7588\n",
      "Epoch 537/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4315.1006 - val_loss: 5115.7832\n",
      "Epoch 538/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4302.5669 - val_loss: 4086.5698\n",
      "Epoch 539/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4314.0850 - val_loss: 3726.7754\n",
      "Epoch 540/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4009.9980 - val_loss: 4048.5168\n",
      "Epoch 541/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4194.1650 - val_loss: 4267.0474\n",
      "Epoch 542/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4289.1890 - val_loss: 3920.8574\n",
      "Epoch 543/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4146.3003 - val_loss: 3996.8079\n",
      "Epoch 544/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4166.2466 - val_loss: 4173.9912\n",
      "Epoch 545/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4292.3662 - val_loss: 4019.3970\n",
      "Epoch 546/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4173.7544 - val_loss: 4023.9705\n",
      "Epoch 547/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4293.6729 - val_loss: 4335.0762\n",
      "Epoch 548/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3954.8689 - val_loss: 3837.8508\n",
      "Epoch 549/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4216.7275 - val_loss: 4221.1104\n",
      "Epoch 550/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4092.6753 - val_loss: 4091.7424\n",
      "Epoch 551/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4379.9517 - val_loss: 3977.5813\n",
      "Epoch 552/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4291.6865 - val_loss: 4196.5923\n",
      "Epoch 553/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4181.4790 - val_loss: 4201.1211\n",
      "Epoch 554/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4050.8940 - val_loss: 3801.0066\n",
      "Epoch 555/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4280.9912 - val_loss: 3785.6072\n",
      "Epoch 556/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4180.9048 - val_loss: 3716.2988\n",
      "Epoch 557/600\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 4125.6196 - val_loss: 4117.9805\n",
      "Epoch 558/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3993.2339 - val_loss: 4236.5088\n",
      "Epoch 559/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4244.6699 - val_loss: 3822.1494\n",
      "Epoch 560/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3999.7537 - val_loss: 3951.0422\n",
      "Epoch 561/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4033.4353 - val_loss: 4057.1296\n",
      "Epoch 562/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4215.2642 - val_loss: 3754.0815\n",
      "Epoch 563/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4147.9150 - val_loss: 4206.3169\n",
      "Epoch 564/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4236.0889 - val_loss: 3834.3179\n",
      "Epoch 565/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4087.7556 - val_loss: 3936.6714\n",
      "Epoch 566/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4106.7305 - val_loss: 3920.8433\n",
      "Epoch 567/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4324.6982 - val_loss: 3962.8767\n",
      "Epoch 568/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4099.4141 - val_loss: 4177.3149\n",
      "Epoch 569/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4179.3018 - val_loss: 4065.3215\n",
      "Epoch 570/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4123.8154 - val_loss: 4014.4709\n",
      "Epoch 571/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4168.1147 - val_loss: 3879.0149\n",
      "Epoch 572/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4133.1221 - val_loss: 3732.4343\n",
      "Epoch 573/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3954.4668 - val_loss: 4218.7939\n",
      "Epoch 574/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4263.5254 - val_loss: 4211.3179\n",
      "Epoch 575/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4200.1997 - val_loss: 3792.3540\n",
      "Epoch 576/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4130.0444 - val_loss: 4265.9907\n",
      "Epoch 577/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4194.3022 - val_loss: 3826.7576\n",
      "Epoch 578/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3998.4880 - val_loss: 4052.8875\n",
      "Epoch 579/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4174.6689 - val_loss: 3850.3479\n",
      "Epoch 580/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4033.2261 - val_loss: 3832.0271\n",
      "Epoch 581/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3980.5803 - val_loss: 3732.8359\n",
      "Epoch 582/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3945.2896 - val_loss: 4306.4946\n",
      "Epoch 583/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4159.2046 - val_loss: 3825.3491\n",
      "Epoch 584/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4131.7607 - val_loss: 3999.0557\n",
      "Epoch 585/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4088.2776 - val_loss: 3870.3665\n",
      "Epoch 586/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4217.4414 - val_loss: 3978.9651\n",
      "Epoch 587/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4036.1279 - val_loss: 3956.8284\n",
      "Epoch 588/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4229.7466 - val_loss: 3797.8894\n",
      "Epoch 589/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4080.6128 - val_loss: 4035.0176\n",
      "Epoch 590/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4054.4949 - val_loss: 3809.3381\n",
      "Epoch 591/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4062.6353 - val_loss: 3632.2705\n",
      "Epoch 592/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4039.2537 - val_loss: 4117.3564\n",
      "Epoch 593/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4230.8115 - val_loss: 4175.6201\n",
      "Epoch 594/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4182.2002 - val_loss: 4043.4121\n",
      "Epoch 595/600\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 4205.0547 - val_loss: 3737.2432\n",
      "Epoch 596/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4250.2070 - val_loss: 3958.0581\n",
      "Epoch 597/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4162.6538 - val_loss: 4069.4346\n",
      "Epoch 598/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4161.7842 - val_loss: 3853.8611\n",
      "Epoch 599/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4067.8892 - val_loss: 4178.1104\n",
      "Epoch 600/600\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4022.7876 - val_loss: 3553.2375\n",
      "CPU times: user 1min 44s, sys: 27.6 s, total: 2min 11s\n",
      "Wall time: 33.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f384eae9820>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time makespan_instance_only_model.fit([X_instance_train_scaled_2channel], [y_makespan_train], epochs=end_epoch, batch_size=model_batch_size, validation_split=VALIDATION_SPLIT, callbacks=[tb_makespan_instance_only], initial_epoch=init_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 3ms/step - loss: 4139.9507\n",
      "CPU times: user 345 ms, sys: 62.9 ms, total: 408 ms\n",
      "Wall time: 153 ms\n",
      "Loss on test set is 4139.95068359375\n"
     ]
    }
   ],
   "source": [
    "%time makespan_instance_only_test_loss = makespan_instance_only_model.evaluate(x=[X_instance_test_scaled_2channel], y=[y_makespan_test], batch_size=model_batch_size)\n",
    "print(\"Loss on test set is {}\".format(makespan_instance_only_test_loss))\n",
    "makespan_instance_only_model.save(MODEL_DIR + GENERAL_MODEL_NAME + str(end_epoch) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init_epoch = 600\n",
    "end_epoch = 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 601/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4130.3638 - val_loss: 4387.2920\n",
      "Epoch 602/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3834.8804 - val_loss: 3811.3467\n",
      "Epoch 603/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4128.6289 - val_loss: 4254.9844\n",
      "Epoch 604/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3942.4805 - val_loss: 4050.6550\n",
      "Epoch 605/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4124.9419 - val_loss: 3782.1787\n",
      "Epoch 606/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3979.6240 - val_loss: 3878.4233\n",
      "Epoch 607/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4222.5732 - val_loss: 3909.2107\n",
      "Epoch 608/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3998.5359 - val_loss: 3894.3721\n",
      "Epoch 609/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4039.8635 - val_loss: 3656.9109\n",
      "Epoch 610/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3923.6841 - val_loss: 4205.2339\n",
      "Epoch 611/700\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 4034.8616 - val_loss: 3697.9319\n",
      "Epoch 612/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4032.2524 - val_loss: 3757.9929\n",
      "Epoch 613/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3954.0852 - val_loss: 3785.3152\n",
      "Epoch 614/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4093.6147 - val_loss: 4027.6440\n",
      "Epoch 615/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3922.4492 - val_loss: 3591.5366\n",
      "Epoch 616/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3938.1611 - val_loss: 3818.0933\n",
      "Epoch 617/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4022.1553 - val_loss: 4037.8655\n",
      "Epoch 618/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4082.1892 - val_loss: 3922.6431\n",
      "Epoch 619/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4136.4258 - val_loss: 3820.4565\n",
      "Epoch 620/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4116.1523 - val_loss: 3985.4177\n",
      "Epoch 621/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4020.8701 - val_loss: 4301.3726\n",
      "Epoch 622/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4113.4082 - val_loss: 4065.4124\n",
      "Epoch 623/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3953.2224 - val_loss: 3859.1316\n",
      "Epoch 624/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4004.6631 - val_loss: 3918.9026\n",
      "Epoch 625/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3908.6040 - val_loss: 3406.7744\n",
      "Epoch 626/700\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 4117.9556 - val_loss: 3989.8474\n",
      "Epoch 627/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3888.6873 - val_loss: 4148.8335\n",
      "Epoch 628/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4031.2971 - val_loss: 3940.5239\n",
      "Epoch 629/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4086.0352 - val_loss: 3652.3169\n",
      "Epoch 630/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3867.0684 - val_loss: 3627.8203\n",
      "Epoch 631/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3876.8708 - val_loss: 3876.8577\n",
      "Epoch 632/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3978.1147 - val_loss: 3516.5955\n",
      "Epoch 633/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4008.6096 - val_loss: 4084.9697\n",
      "Epoch 634/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4039.8560 - val_loss: 3534.8765\n",
      "Epoch 635/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4049.4531 - val_loss: 3868.2925\n",
      "Epoch 636/700\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 4072.7417 - val_loss: 3792.8162\n",
      "Epoch 637/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3944.7048 - val_loss: 3385.2290\n",
      "Epoch 638/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3995.6804 - val_loss: 4032.5378\n",
      "Epoch 639/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4008.9688 - val_loss: 4137.3062\n",
      "Epoch 640/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4132.1270 - val_loss: 3637.8721\n",
      "Epoch 641/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3849.6897 - val_loss: 3826.4243\n",
      "Epoch 642/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3802.8655 - val_loss: 3682.7908\n",
      "Epoch 643/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3890.4575 - val_loss: 3853.9153\n",
      "Epoch 644/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3803.6897 - val_loss: 3704.9182\n",
      "Epoch 645/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3743.8152 - val_loss: 3825.7605\n",
      "Epoch 646/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4018.6968 - val_loss: 3757.0386\n",
      "Epoch 647/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3905.0305 - val_loss: 3791.5586\n",
      "Epoch 648/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3933.7268 - val_loss: 3910.3171\n",
      "Epoch 649/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3751.6831 - val_loss: 3819.1055\n",
      "Epoch 650/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3946.8652 - val_loss: 3803.8406\n",
      "Epoch 651/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4001.3264 - val_loss: 3723.3303\n",
      "Epoch 652/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3913.1423 - val_loss: 3807.9749\n",
      "Epoch 653/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3920.7444 - val_loss: 3920.1704\n",
      "Epoch 654/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4023.0632 - val_loss: 3654.0183\n",
      "Epoch 655/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3958.2844 - val_loss: 3645.3474\n",
      "Epoch 656/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4047.6421 - val_loss: 3739.2532\n",
      "Epoch 657/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4117.8047 - val_loss: 4033.3577\n",
      "Epoch 658/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4020.7312 - val_loss: 3712.3320\n",
      "Epoch 659/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3895.2783 - val_loss: 4219.0317\n",
      "Epoch 660/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3920.5256 - val_loss: 3760.2107\n",
      "Epoch 661/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3952.2173 - val_loss: 4178.9233\n",
      "Epoch 662/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3854.1897 - val_loss: 3939.5166\n",
      "Epoch 663/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3842.7175 - val_loss: 3518.7644\n",
      "Epoch 664/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3841.3269 - val_loss: 3968.9014\n",
      "Epoch 665/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 4037.8372 - val_loss: 3767.4106\n",
      "Epoch 666/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3913.2163 - val_loss: 3660.0444\n",
      "Epoch 667/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3791.3271 - val_loss: 3814.9690\n",
      "Epoch 668/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3865.9548 - val_loss: 3878.3606\n",
      "Epoch 669/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3892.5815 - val_loss: 3727.8313\n",
      "Epoch 670/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3835.6499 - val_loss: 3417.1726\n",
      "Epoch 671/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3816.1045 - val_loss: 3616.9746\n",
      "Epoch 672/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3828.1353 - val_loss: 4132.4312\n",
      "Epoch 673/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3909.9792 - val_loss: 3875.8862\n",
      "Epoch 674/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3950.9812 - val_loss: 3678.3660\n",
      "Epoch 675/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3863.6731 - val_loss: 3427.9407\n",
      "Epoch 676/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3775.8911 - val_loss: 3662.2649\n",
      "Epoch 677/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3946.1460 - val_loss: 3723.4797\n",
      "Epoch 678/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3781.7683 - val_loss: 3588.3376\n",
      "Epoch 679/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3844.6736 - val_loss: 3696.1116\n",
      "Epoch 680/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3884.4756 - val_loss: 3752.5664\n",
      "Epoch 681/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3783.2939 - val_loss: 3564.6392\n",
      "Epoch 682/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3946.9507 - val_loss: 3865.0249\n",
      "Epoch 683/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3720.3848 - val_loss: 3816.9702\n",
      "Epoch 684/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3793.9255 - val_loss: 3562.3823\n",
      "Epoch 685/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3882.3943 - val_loss: 3813.4744\n",
      "Epoch 686/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3822.1936 - val_loss: 3764.0718\n",
      "Epoch 687/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3765.1628 - val_loss: 3397.2485\n",
      "Epoch 688/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3847.3464 - val_loss: 3742.3491\n",
      "Epoch 689/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3893.2048 - val_loss: 4101.1226\n",
      "Epoch 690/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3780.6235 - val_loss: 4071.8838\n",
      "Epoch 691/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3771.6667 - val_loss: 3766.5347\n",
      "Epoch 692/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3756.7383 - val_loss: 3898.3777\n",
      "Epoch 693/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3704.0403 - val_loss: 4237.5332\n",
      "Epoch 694/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3734.8208 - val_loss: 3729.2329\n",
      "Epoch 695/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3747.9417 - val_loss: 3969.2632\n",
      "Epoch 696/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3771.7119 - val_loss: 3645.5425\n",
      "Epoch 697/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3742.2432 - val_loss: 3437.9509\n",
      "Epoch 698/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3663.6548 - val_loss: 3570.2402\n",
      "Epoch 699/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3699.3364 - val_loss: 3617.8018\n",
      "Epoch 700/700\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3635.1360 - val_loss: 3990.6340\n",
      "CPU times: user 1min 43s, sys: 28.6 s, total: 2min 11s\n",
      "Wall time: 34 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f384a4ca4f0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time makespan_instance_only_model.fit([X_instance_train_scaled_2channel], [y_makespan_train], epochs=end_epoch, batch_size=model_batch_size, validation_split=VALIDATION_SPLIT, callbacks=[tb_makespan_instance_only], initial_epoch=init_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 3ms/step - loss: 3642.1270\n",
      "CPU times: user 283 ms, sys: 125 ms, total: 408 ms\n",
      "Wall time: 155 ms\n",
      "Loss on test set is 3642.126953125\n"
     ]
    }
   ],
   "source": [
    "%time makespan_instance_only_test_loss = makespan_instance_only_model.evaluate(x=[X_instance_test_scaled_2channel], y=[y_makespan_test], batch_size=model_batch_size)\n",
    "print(\"Loss on test set is {}\".format(makespan_instance_only_test_loss))\n",
    "makespan_instance_only_model.save(MODEL_DIR + GENERAL_MODEL_NAME + str(end_epoch) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init_epoch = 800\n",
    "end_epoch = 900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 801/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3772.2688 - val_loss: 3742.3562\n",
      "Epoch 802/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3554.7063 - val_loss: 3674.4082\n",
      "Epoch 803/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3727.4299 - val_loss: 3514.7737\n",
      "Epoch 804/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3766.7612 - val_loss: 4163.7593\n",
      "Epoch 805/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3740.4585 - val_loss: 3952.5059\n",
      "Epoch 806/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3704.2412 - val_loss: 3481.2461\n",
      "Epoch 807/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3680.5747 - val_loss: 3344.5061\n",
      "Epoch 808/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3890.0259 - val_loss: 3177.8538\n",
      "Epoch 809/900\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 3750.0615 - val_loss: 3482.0693\n",
      "Epoch 810/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3696.1831 - val_loss: 3535.6545\n",
      "Epoch 811/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3706.2839 - val_loss: 3622.9355\n",
      "Epoch 812/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3627.2173 - val_loss: 3317.0398\n",
      "Epoch 813/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3746.8145 - val_loss: 3431.1147\n",
      "Epoch 814/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3909.0591 - val_loss: 3629.4016\n",
      "Epoch 815/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3597.7268 - val_loss: 3590.1335\n",
      "Epoch 816/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3780.2600 - val_loss: 3664.6809\n",
      "Epoch 817/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3700.6880 - val_loss: 3636.6968\n",
      "Epoch 818/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3734.0151 - val_loss: 3665.9148\n",
      "Epoch 819/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3762.4087 - val_loss: 3356.8813\n",
      "Epoch 820/900\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 3525.5264 - val_loss: 3708.0083\n",
      "Epoch 821/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3550.6780 - val_loss: 3536.0544\n",
      "Epoch 822/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3692.1104 - val_loss: 3577.6809\n",
      "Epoch 823/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3653.0493 - val_loss: 3673.6838\n",
      "Epoch 824/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3532.9648 - val_loss: 3668.1899\n",
      "Epoch 825/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3673.9905 - val_loss: 3678.7502\n",
      "Epoch 826/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3548.2332 - val_loss: 3683.7566\n",
      "Epoch 827/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3579.6628 - val_loss: 3819.5701\n",
      "Epoch 828/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3543.2361 - val_loss: 3640.8977\n",
      "Epoch 829/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3588.1836 - val_loss: 3423.7283\n",
      "Epoch 830/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3773.7981 - val_loss: 3431.4299\n",
      "Epoch 831/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3756.3401 - val_loss: 3738.8965\n",
      "Epoch 832/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3579.9104 - val_loss: 3571.9006\n",
      "Epoch 833/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3485.1887 - val_loss: 3443.6755\n",
      "Epoch 834/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3569.1655 - val_loss: 3194.2900\n",
      "Epoch 835/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3642.9343 - val_loss: 3204.7771\n",
      "Epoch 836/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3831.9221 - val_loss: 3198.9028\n",
      "Epoch 837/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3684.0903 - val_loss: 3294.8928\n",
      "Epoch 838/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3574.8428 - val_loss: 3610.0417\n",
      "Epoch 839/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3585.5852 - val_loss: 3345.0527\n",
      "Epoch 840/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3608.2988 - val_loss: 3655.2073\n",
      "Epoch 841/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3645.2073 - val_loss: 3652.9678\n",
      "Epoch 842/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3632.6936 - val_loss: 3614.4373\n",
      "Epoch 843/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3740.9067 - val_loss: 3379.8523\n",
      "Epoch 844/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3560.4309 - val_loss: 3679.1672\n",
      "Epoch 845/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3644.4736 - val_loss: 3381.8696\n",
      "Epoch 846/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3670.0715 - val_loss: 3681.4065\n",
      "Epoch 847/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3418.2036 - val_loss: 3481.5161\n",
      "Epoch 848/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3403.6052 - val_loss: 3239.2798\n",
      "Epoch 849/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3347.5330 - val_loss: 3596.6804\n",
      "Epoch 850/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3453.2537 - val_loss: 3488.9238\n",
      "Epoch 851/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3653.1072 - val_loss: 3511.1946\n",
      "Epoch 852/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3420.1975 - val_loss: 3439.9526\n",
      "Epoch 853/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3488.4221 - val_loss: 3362.7366\n",
      "Epoch 854/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3690.2029 - val_loss: 3822.9570\n",
      "Epoch 855/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3545.9187 - val_loss: 3733.6289\n",
      "Epoch 856/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3635.5251 - val_loss: 3369.2744\n",
      "Epoch 857/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3614.8125 - val_loss: 3875.4456\n",
      "Epoch 858/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3403.8928 - val_loss: 3419.5979\n",
      "Epoch 859/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3630.1079 - val_loss: 3697.7644\n",
      "Epoch 860/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3607.9419 - val_loss: 3788.2224\n",
      "Epoch 861/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3490.2568 - val_loss: 3455.0479\n",
      "Epoch 862/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3512.4084 - val_loss: 2964.5044\n",
      "Epoch 863/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3658.5127 - val_loss: 3479.2476\n",
      "Epoch 864/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3477.3113 - val_loss: 3599.7251\n",
      "Epoch 865/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3460.6616 - val_loss: 3090.6877\n",
      "Epoch 866/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3525.6045 - val_loss: 3298.2878\n",
      "Epoch 867/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3496.0640 - val_loss: 3295.1465\n",
      "Epoch 868/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3469.1904 - val_loss: 3212.8147\n",
      "Epoch 869/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3390.9761 - val_loss: 3157.1357\n",
      "Epoch 870/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3420.2468 - val_loss: 3539.0103\n",
      "Epoch 871/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3390.4561 - val_loss: 3624.6138\n",
      "Epoch 872/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3323.9905 - val_loss: 3311.1497\n",
      "Epoch 873/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3412.3799 - val_loss: 3624.5974\n",
      "Epoch 874/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3528.0815 - val_loss: 3452.4570\n",
      "Epoch 875/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3550.6348 - val_loss: 3447.9504\n",
      "Epoch 876/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3483.5183 - val_loss: 3256.6538\n",
      "Epoch 877/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3267.9331 - val_loss: 3310.1169\n",
      "Epoch 878/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3450.9043 - val_loss: 3621.5073\n",
      "Epoch 879/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3444.7100 - val_loss: 3275.6697\n",
      "Epoch 880/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3326.5093 - val_loss: 3316.0750\n",
      "Epoch 881/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3494.0168 - val_loss: 3296.9465\n",
      "Epoch 882/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3348.0193 - val_loss: 3182.0400\n",
      "Epoch 883/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3337.1580 - val_loss: 3376.5911\n",
      "Epoch 884/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3383.9663 - val_loss: 3171.2444\n",
      "Epoch 885/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3441.3760 - val_loss: 3355.7786\n",
      "Epoch 886/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3417.0691 - val_loss: 3407.5583\n",
      "Epoch 887/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3336.2107 - val_loss: 3454.2200\n",
      "Epoch 888/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3369.3799 - val_loss: 3370.1272\n",
      "Epoch 889/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3400.8347 - val_loss: 3393.1804\n",
      "Epoch 890/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3373.0796 - val_loss: 3416.1943\n",
      "Epoch 891/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3256.1692 - val_loss: 3511.7205\n",
      "Epoch 892/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3248.2205 - val_loss: 3166.0229\n",
      "Epoch 893/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3269.8235 - val_loss: 3495.3396\n",
      "Epoch 894/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3430.6509 - val_loss: 3628.2930\n",
      "Epoch 895/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3497.0093 - val_loss: 3280.7646\n",
      "Epoch 896/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3352.7229 - val_loss: 3294.0210\n",
      "Epoch 897/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3132.6401 - val_loss: 3301.4199\n",
      "Epoch 898/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3221.7974 - val_loss: 3198.2749\n",
      "Epoch 899/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3233.8230 - val_loss: 3296.8420\n",
      "Epoch 900/900\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3267.4246 - val_loss: 3234.5120\n",
      "CPU times: user 1min 43s, sys: 28.6 s, total: 2min 11s\n",
      "Wall time: 34 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f384f45c460>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time makespan_instance_only_model.fit([X_instance_train_scaled_2channel], [y_makespan_train], epochs=end_epoch, batch_size=model_batch_size, validation_split=VALIDATION_SPLIT, callbacks=[tb_makespan_instance_only], initial_epoch=init_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 3ms/step - loss: 3239.6860\n",
      "CPU times: user 300 ms, sys: 109 ms, total: 409 ms\n",
      "Wall time: 154 ms\n",
      "Loss on test set is 3239.68603515625\n"
     ]
    }
   ],
   "source": [
    "%time makespan_instance_only_test_loss = makespan_instance_only_model.evaluate(x=[X_instance_test_scaled_2channel], y=[y_makespan_test], batch_size=model_batch_size)\n",
    "print(\"Loss on test set is {}\".format(makespan_instance_only_test_loss))\n",
    "makespan_instance_only_model.save(MODEL_DIR + GENERAL_MODEL_NAME + str(end_epoch) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init_epoch = 900\n",
    "end_epoch = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 901/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3410.3423 - val_loss: 3161.3672\n",
      "Epoch 902/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3280.7227 - val_loss: 3897.3938\n",
      "Epoch 903/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3199.6509 - val_loss: 3182.2837\n",
      "Epoch 904/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3282.1355 - val_loss: 3157.0581\n",
      "Epoch 905/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3269.2393 - val_loss: 3327.8677\n",
      "Epoch 906/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3325.1345 - val_loss: 3236.0139\n",
      "Epoch 907/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3460.5056 - val_loss: 3000.6873\n",
      "Epoch 908/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3264.1501 - val_loss: 3107.2385\n",
      "Epoch 909/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3269.7417 - val_loss: 3404.6392\n",
      "Epoch 910/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3243.1707 - val_loss: 3268.2830\n",
      "Epoch 911/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3222.1677 - val_loss: 3241.0825\n",
      "Epoch 912/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3199.2026 - val_loss: 3394.7490\n",
      "Epoch 913/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3229.3315 - val_loss: 3186.3545\n",
      "Epoch 914/1000\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 3261.0989 - val_loss: 3428.0161\n",
      "Epoch 915/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3260.8569 - val_loss: 3046.0684\n",
      "Epoch 916/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3093.5913 - val_loss: 3039.1238\n",
      "Epoch 917/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3276.7461 - val_loss: 3026.1223\n",
      "Epoch 918/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3293.2024 - val_loss: 3191.3284\n",
      "Epoch 919/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3341.1011 - val_loss: 3289.5801\n",
      "Epoch 920/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3124.5935 - val_loss: 3160.2715\n",
      "Epoch 921/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3175.0334 - val_loss: 3080.7854\n",
      "Epoch 922/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3140.2119 - val_loss: 3095.8374\n",
      "Epoch 923/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3139.4941 - val_loss: 3198.8052\n",
      "Epoch 924/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3216.0554 - val_loss: 3275.9429\n",
      "Epoch 925/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3223.0474 - val_loss: 3093.5581\n",
      "Epoch 926/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3117.6375 - val_loss: 3287.5317\n",
      "Epoch 927/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3208.9607 - val_loss: 3093.0183\n",
      "Epoch 928/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3185.9595 - val_loss: 3177.3770\n",
      "Epoch 929/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3181.1494 - val_loss: 3067.6504\n",
      "Epoch 930/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3101.3569 - val_loss: 3295.6189\n",
      "Epoch 931/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3184.8357 - val_loss: 3169.8813\n",
      "Epoch 932/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3048.1406 - val_loss: 3151.9651\n",
      "Epoch 933/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3193.4497 - val_loss: 3055.7800\n",
      "Epoch 934/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3154.4802 - val_loss: 3019.5547\n",
      "Epoch 935/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3123.4917 - val_loss: 3391.7000\n",
      "Epoch 936/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3115.2610 - val_loss: 2935.7295\n",
      "Epoch 937/1000\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 2926.3376 - val_loss: 2987.5784\n",
      "Epoch 938/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3163.9907 - val_loss: 3129.1577\n",
      "Epoch 939/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3055.2891 - val_loss: 3093.3232\n",
      "Epoch 940/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3148.9626 - val_loss: 3146.9771\n",
      "Epoch 941/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2957.7783 - val_loss: 3011.7871\n",
      "Epoch 942/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3020.7170 - val_loss: 3298.8247\n",
      "Epoch 943/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3075.0974 - val_loss: 3078.7920\n",
      "Epoch 944/1000\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 2976.0398 - val_loss: 2887.4761\n",
      "Epoch 945/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3155.7644 - val_loss: 3033.4727\n",
      "Epoch 946/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3168.2971 - val_loss: 2749.8826\n",
      "Epoch 947/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3067.6650 - val_loss: 3047.8560\n",
      "Epoch 948/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2966.1433 - val_loss: 3167.0645\n",
      "Epoch 949/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2987.8474 - val_loss: 3093.8181\n",
      "Epoch 950/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3051.7607 - val_loss: 3192.9824\n",
      "Epoch 951/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2986.7200 - val_loss: 3005.9834\n",
      "Epoch 952/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2986.2629 - val_loss: 3124.5918\n",
      "Epoch 953/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3008.6499 - val_loss: 2874.1702\n",
      "Epoch 954/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2949.9502 - val_loss: 3103.7998\n",
      "Epoch 955/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2921.4192 - val_loss: 3194.5139\n",
      "Epoch 956/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2883.3391 - val_loss: 3202.4353\n",
      "Epoch 957/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3014.8389 - val_loss: 3266.5303\n",
      "Epoch 958/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 3177.6663 - val_loss: 3232.7048\n",
      "Epoch 959/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2950.1477 - val_loss: 2707.7563\n",
      "Epoch 960/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2935.0051 - val_loss: 2864.2849\n",
      "Epoch 961/1000\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 2868.1709 - val_loss: 2961.8372\n",
      "Epoch 962/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2981.1143 - val_loss: 2898.8403\n",
      "Epoch 963/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2901.6646 - val_loss: 3007.4421\n",
      "Epoch 964/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2929.3445 - val_loss: 3090.3342\n",
      "Epoch 965/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2920.0764 - val_loss: 3133.1316\n",
      "Epoch 966/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2964.4326 - val_loss: 2887.4197\n",
      "Epoch 967/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2936.8472 - val_loss: 2840.8901\n",
      "Epoch 968/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2823.1909 - val_loss: 2910.5457\n",
      "Epoch 969/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2843.3965 - val_loss: 2803.9260\n",
      "Epoch 970/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2937.7844 - val_loss: 2824.3953\n",
      "Epoch 971/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2913.2649 - val_loss: 2729.3669\n",
      "Epoch 972/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2911.7097 - val_loss: 2700.4255\n",
      "Epoch 973/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2887.1204 - val_loss: 2924.4163\n",
      "Epoch 974/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2825.5508 - val_loss: 2801.0571\n",
      "Epoch 975/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2872.2173 - val_loss: 3164.0308\n",
      "Epoch 976/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2849.0933 - val_loss: 2752.9656\n",
      "Epoch 977/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2993.3823 - val_loss: 3295.6003\n",
      "Epoch 978/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2902.9087 - val_loss: 2977.9500\n",
      "Epoch 979/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2790.4033 - val_loss: 2767.5391\n",
      "Epoch 980/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2696.8257 - val_loss: 2939.0085\n",
      "Epoch 981/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2714.0381 - val_loss: 3125.8789\n",
      "Epoch 982/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2772.9927 - val_loss: 2814.4763\n",
      "Epoch 983/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2755.5935 - val_loss: 2971.9829\n",
      "Epoch 984/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2771.6099 - val_loss: 3028.3835\n",
      "Epoch 985/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2628.1882 - val_loss: 2813.5242\n",
      "Epoch 986/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2789.1440 - val_loss: 2840.8640\n",
      "Epoch 987/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2778.1165 - val_loss: 3110.6060\n",
      "Epoch 988/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2729.8169 - val_loss: 2852.4309\n",
      "Epoch 989/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2718.7866 - val_loss: 2747.9524\n",
      "Epoch 990/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2670.8394 - val_loss: 2921.2830\n",
      "Epoch 991/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2649.0137 - val_loss: 2765.3345\n",
      "Epoch 992/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2727.8767 - val_loss: 2797.2949\n",
      "Epoch 993/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2778.6533 - val_loss: 2644.3379\n",
      "Epoch 994/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2829.1934 - val_loss: 2667.0864\n",
      "Epoch 995/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2800.7517 - val_loss: 2784.7317\n",
      "Epoch 996/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2737.9773 - val_loss: 2879.4963\n",
      "Epoch 997/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2684.2383 - val_loss: 2550.8730\n",
      "Epoch 998/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2639.2000 - val_loss: 2750.0679\n",
      "Epoch 999/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2736.9417 - val_loss: 2761.5498\n",
      "Epoch 1000/1000\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2656.6594 - val_loss: 2789.3342\n",
      "CPU times: user 1min 42s, sys: 28.9 s, total: 2min 11s\n",
      "Wall time: 33.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f384f422700>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time makespan_instance_only_model.fit([X_instance_train_scaled_2channel], [y_makespan_train], epochs=end_epoch, batch_size=model_batch_size, validation_split=VALIDATION_SPLIT, callbacks=[tb_makespan_instance_only], initial_epoch=init_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 3ms/step - loss: 3004.7800\n",
      "CPU times: user 348 ms, sys: 63.4 ms, total: 411 ms\n",
      "Wall time: 154 ms\n",
      "Loss on test set is 3004.780029296875\n"
     ]
    }
   ],
   "source": [
    "%time makespan_instance_only_test_loss = makespan_instance_only_model.evaluate(x=[X_instance_test_scaled_2channel], y=[y_makespan_test], batch_size=model_batch_size)\n",
    "print(\"Loss on test set is {}\".format(makespan_instance_only_test_loss))\n",
    "makespan_instance_only_model.save(MODEL_DIR + GENERAL_MODEL_NAME + str(end_epoch) + '.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the model for predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking through the loss for train and validation, it seems that the model begins to overfit after 600 epochs of training. So, we decide to use the model after 6000 epochs of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "FOLDER = './model/'\n",
    "model_batch_size = 100\n",
    "\n",
    "my_model = load_model(FOLDER + 'model_checkpoint/makespan_instance_only_Q_600.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 462 ms, sys: 16.5 ms, total: 479 ms\n",
      "Wall time: 236 ms\n"
     ]
    }
   ],
   "source": [
    "%time a = my_model.predict(x=[X_instance_test_scaled_2channel], batch_size=model_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0006423000013455749\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "start = timeit.timeit()\n",
    "\n",
    "for i in range(999):\n",
    "    a = np.concatenate((a, my_model.predict(x=[X_instance_test_scaled_2channel], batch_size=model_batch_size)), axis=1)\n",
    "\n",
    "end = timeit.timeit()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_to_test = X_instance_name_list_test.copy()\n",
    "benchmark_to_test['pred_makespan'] = a.tolist()\n",
    "benchmark_to_test['true_makespan'] = y_makespan_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Instance</th>\n",
       "      <th>pred_makespan</th>\n",
       "      <th>true_makespan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6252</th>\n",
       "      <td>q6252</td>\n",
       "      <td>[776.649658203125, 820.9853515625, 732.4948730...</td>\n",
       "      <td>705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4684</th>\n",
       "      <td>q4684</td>\n",
       "      <td>[693.7030639648438, 824.7876586914062, 736.686...</td>\n",
       "      <td>786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>q1731</td>\n",
       "      <td>[656.3553466796875, 783.6185913085938, 700.319...</td>\n",
       "      <td>741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4742</th>\n",
       "      <td>q4742</td>\n",
       "      <td>[674.0472412109375, 639.7532958984375, 673.131...</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4521</th>\n",
       "      <td>q4521</td>\n",
       "      <td>[781.022705078125, 736.7913208007812, 736.5009...</td>\n",
       "      <td>731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Instance                                      pred_makespan  \\\n",
       "6252    q6252  [776.649658203125, 820.9853515625, 732.4948730...   \n",
       "4684    q4684  [693.7030639648438, 824.7876586914062, 736.686...   \n",
       "1731    q1731  [656.3553466796875, 783.6185913085938, 700.319...   \n",
       "4742    q4742  [674.0472412109375, 639.7532958984375, 673.131...   \n",
       "4521    q4521  [781.022705078125, 736.7913208007812, 736.5009...   \n",
       "\n",
       "      true_makespan  \n",
       "6252            705  \n",
       "4684            786  \n",
       "1731            741  \n",
       "4742            698  \n",
       "4521            731  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_to_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "benchmark_to_test.to_pickle(FOLDER + \"benchmark_to_test_with_uncertainty.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
